<!DOCTYPE html>
<html>

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>Software Engineering in Practice</title>
    <style>
		html {
			font-size: 16px;
		}

		@media screen and (min-width: 320px) {
			html {
				font-size: calc(16px + 6 * ((100vw - 320px) / 680));
			}
		}

		@media screen and (min-width: 1000px) {
			html {
				font-size: 22px;
			}
		}
	</style>
</head>
<body>
    <h1>Software Engineering In Practice, (contact: adrianjewell91 at gmail dot com)</h1>
		<h2>July 7, 2022</h2>
Regarding the median of 2 sorted arrays, it took a long time to wrap my head around this problem, but finally, it did happen. First of all, there are a lot of edge cases. For two arrays, there were maybe 6 edge cases where the output involved taking either the first or first two elements in one or both of the arrays. Actually, it was probably better to call them base cases, because they represent the simplest cases where iteration through the arrays isn’t necessary. Additionally, a base case may be a better label because they aren’t hardcoded into the optimal solution. I know this because I read some of the solutions, and they don’t hard code any of the base cases. That really annoyed me because I still haven’t figured out how to code the optimal solution, but I will eventually. 
	</br>	</br>
Right now, I’ve wrapped my head around the linear solution. In a nutshell, the solution is to pretend the two arrays are one array, then iterate halfway through the two arrays, and track which pointer references the actual median. Usually, it is the lower of the two numbers, but it could become the higher of the two if you run out of numbers in one of the arrays. After iterating halfway, there is some logic to calculate the median after the iteration. This logic is because the array is divided between two arrays, so you have to account for the reality of this. It breaks down roughly into this logic below. Clearly, I didn’t even understand it completely myself, which is why I took the time to write it out here. As a disclaimer, it is more of a series of questions rather than a control flow, diagram. 
	</br>	</br>
1. Are the numbers equal to each other?
2. Is the total count odd? 
    1. Was the first pointer still pointing to the median?
3. Since it is even, was the first pointer still pointing to the median?
    1. Is that pointer at the end of an array?
    2. Is the first pointer’s number still less than the second pointer’s numbr, and is the other pointer greater than the next number after the first pointer?
4. Do the above question apply but with the pointers flipped?
	</br>	</br>

https://leetcode.com/submissions/detail/739491323/
		</br>	</br>
	<h2>July 1, 2022</h2>
		Perhaps the real challenge in software is to deliver things incrementally, and by the word ‘incrementally’ it is meant the building of software in such a way as to deliver real and usable value to the user, with each iteration. That it is extremely hard to accomplish this is an opinion of mine, of which it is my goal to explain though some examples. In fact, the challenge appears again and again in situations around me, but it is hard for me to explain the reasons for its difficulty. Still it is worth an attempt, and maybe the reasons will become clear…probably it is just laziness or delusions of grandeur. But in any case, there are many examples and they will be outlined here, as well as the consequences that befell the people trying to build it.
	</br>	</br>
		Building to accommodate for lessons learned in the past was a blocker to delivering incremental value. In a design for a large-scale write service (14 million writes/day), my team wanted to handle the many different work-flows needed to deliver the full suite of use cases. The solution for this, from a design perspective, was to use many event queues to decouple the compute, and the designer said that the reason for this was so as to not replicate the very annoying design of one internal topic accommodating multiple types of messages, which was the case in one of our legacy systems. This was vaild concern, however, implementing this design didn’t work as the team got started, and after 5 weeks or so of work, there was no working prototype, and lots of boilerplate code for handling different use cases. It would have been much better to simply build one use case, request to save, one service, no kafka topics, and have something for the team to start using, rather than wait for the whole thing, which still will take another six months. Then, refactor as more use cases were accommodated. But, the team wanted to do it this way, and they learned a lesso, hopefully. 
	</br>	</br>
		When estimating work, one should consider the real business need in order to deliver incrementally. For example, there was a ticket to estimate some work for checking stale data in one of the caches. Upon reading this ticket, one of the engineers claimed that the ticket would be more of an epic than a ticket, and suggested splitting it up. I disagreed saying that the work could be accomplished in one sprint and still deliver a unit of value to the user. In fact, this was true; yes, the work could be the size of an epic, but it could also just be a quick tool to check a few main values, and stick it on a dashboard. Both perspectives are true, but the latter will suffice for the user. This is why knowing the business need can really help decide what to do now and what can wait. In this case, what could wait was the thoroughness, and what couldn’t wait was a preliminary indicator of the key values. The team did get the work done, and it was used immediately and successfully.
 	</br>	</br>
		Delusions of grandeur certainly are a big problem. Recently, the team had to “plan the quarter,” and there are quotes around that because obviously it didn’t get done, and the reason for that was because the planning was too grand. The problem is that they were thinking too largely. The team should have been able to at least take a slice of the problem posed by business and come up with something to deliver in the first few sprints, but that didn’t happen. Instead, everyone tried to wrap their head around the whole thing and figure out a plan. As a result, the team didn’t get any tickets on the board, and still have planning. Here is the thing about software: it’s never done, and requirements are always changing, so it’s worth thinking about a project in terms of done or not done. It’s better to think about how to make the user happy right now, but make it easy to change, and be able to refactor when the new requirement comes around the corner. 
	</br>	</br>
		Design docs should also reflect the plan for incremental delivery. One team member spent many weeks on a design doc, only for it to be torn down by the leadership in twenty minutes. The reason for this wasn’t as much to do with the engineering but with the product team and engineering not being align. Product team, for instance, was not being fully confident in the problem, but engineering thought the problem was clear, so they let their imaginations run wild. The solution is be as vague as the problem. If the problem is vague, then the software can be vague, and then the iteration can happen not in terms of quantity of features (create, read, write, then delete etc, search etc), but in terms of the specificity - so like, first check one data point, then add another, then sort it etc. If the engineer thought along these lines, then he would have saved a lot of time by being only as specific as the problem statement in the design.
	</br>	</br>
		The initial draft was no better. In a staging/approval system it is better to roll out for one domain rather than many at once, but they tried to do many at once. Why did people do that, I don’t know.  I have a feeling we are going to waterfall things again. It will be all these moving parts that don’t work together until the final hour. It would be better build something that works asap, then refactor it.
	</br>	</br>
		But it can be done correctly. For example, there was an initiative to deliver SLI for a cache updator service, and there ways to deliver incrementally. The first way was to refactor the app into many apps, three to be exact. This would divide the current SLI into three sets of SLI, and thereby give a better window into what was good and what was bad. After this, we iterated on 2 SLIs: completeness, and another for staleness. In completeness, iteration was done first by checking against a list of high impact skus, then setting up a metric to log cache misses in real time. In staleness, first we used lag as a proxy for staleness, then we used TTR as a proxy once we fixed the lag. Within this, the work from the above mentioned example (for checking data staleness) also served to further iterate on the metric for staleness. At the end of epic, there was an inital draft for staleness and completeness, and a few opportunities for code improvement were identified. They were addressed and completed as well.

<h2>June 28 2022</h2>

The common language between the computer science, software, and the domains is “data.” Computer scientists work with the data, product managers help convert domains into data, and the domain owner definitely has a problem that can be solved by thinking of their stuff in terms of data. That is the unifying link between the software engineers and people for whom we work. 

Now in the structure of software engineering corporations, some things are better left to teams and other things are better left to top down. For example, it is worth it for financial requirements to come from the top down because they have the balance sheets, but it better to let the teams decide how to reduce costs. This is a clear example but it is not always clear. For example, it is less clean it the decoupling effort. For instance, it is clear that decoupling needs to happen, but that is not enough info from the top down, because it did not happen over the past 2 years when that was all that they said. So, the top down should say a few more things, such that teams must put every table behind a service, and that we will deprecate MSSQL in one year. That is good info for teams to work with because now they have a better constraint. Still, however, the details of coping with those ultimatums should be with the teams, because management does not know the details of the code, so only teams will know how best to apply the new abstractions and make it work. 

So, with this problem it is a little bit trickier because there are more options. For instance, dev plats could roll out an abstraction for the table and tell everyone to use it, and that would probably work, but it may not be a good idea for management to dictate adoption of the template simply because templates can’t fit every single use case. But, it would still be really good for plats team to roll out the template because it will automate a lot of work and that will be good for efficiency. Perhaps, that’s what it really is about; that is, some things are more efficiently executed from above, and some are better left to the teams, and it depends on the how the problem and knowledge thereof is distributed. 


<h2>June 14 2022</h2>
There is an open question about the exact relationship between quantitative measures of capabilities and the underlying physical systems . An example of this is the ability of Google Cloud Spanner to handle trillions of rows. It is an impressive capability, no doubt, but it is not clear how the technology enables such a capability. Presumably, it is dependent on two factors. One factor is the organization of the hardware itself, and the other factor is the way in which the hardware is used (what software is written into, etc). Put these two together, and what emerges is a tool that can perform to certain specifications, hopefully to the extent that there is business value, and the tool gets used.

Unfortunately, it is not always clear how the technology enables the capability. In my experience, for example, trillions of rows is enough of a quantity to acknowledge that some technology must be at work beyond what is at work in a simple query against the data stores at my job. For instance, a query for 10 million rows can sometimes take minutes, so querying trillions of rows, possibly at a much faster rate, certainly requires some better type of engineering. For me, there may be some immediate insights by looking at source code, but I have yet to do that work, and even then I may not be satisfied with my findings.

Perhaps I have to define more closely the comparison. That is, it is not sufficient to simply compare the capabilities “handle trillions of rows” with “minutes to query ten million records”. At face value, not much insight will be gained from comparing such statements because those aren’t really describing the same capability. In fact, so many things could vary between them. Such variables include the datacenter, the location of the client, the data itself, and perhaps load and throughput, and network conditions, to name a few. So, in order to really understand why spanner beats my own data stores, the concept of handling trillions of rows needs to be reconciled with the concept of taking minutes to query 10 millions rows, whether that be understanding the difference between them, or finding a middle ground.

It could be either, but probably finding a shared middle ground will yield better insight. So there should really be a more cohesive statement such as “querying 10 million rows, which will yield unique result every time, but it will be the same read query, at X times per second, and where the queries could be made from anywhere in the world, and there is a requirement to optimize the query response time, where there are going to be trillions of rows to pick from, and the data is not necessarily internally correlated.” Now, this requirement would yield a better chance of comparing the capabilities of Spanner to my company’s current set up because now both of them can use the same query and maybe even the same data. It is not hard to see why this is the case; it is simply because there is now a single statement that reconciles the boasts of Spanner with the current use case at work.

Another open question is what might be called the “thresholds of scale”. Is it, for example, a challenge to handle 10 customers versus 100 customers, or what about when the order of magnitude increases? So when someone says that a tech company has a fundamentally different issue when the customer base is 500 million people, is that level of scale fundamentally different than a customer of 100 million people? Maybe it is, maybe it isn’t, and maybe the problem is just horizontal scaling, or maybe the problem is rewriting the algorithm to be more performant.

<h2>June 8 2022</h2>
Basically, there was an issue with the Consumer wrapper. As a refresher, the issue is that CPU goes up and then stay elevated after the flow is complete. I discovered this by removing all logic and load testing with messages (they get consumed but trigger no logic). In doing this, I saw increase CPU and contention metrics that didn’t resolve. This led me to think that the messages were not being cleared; that there may be deadlock or no collection.

I confirmed this by implementing a simple consumer and replacing some of the app with the simple consumer, in the consumer I also added some logic to refresh a sku and publish to the event stream. In testing , I saw that the problem was fixed: metrics behave correctly (CPU goes up then down after consumption), and the garbage collection metrics behave normally as well. So this was a very great discovery.

Actually, the GC metrics might not be the greatest, but that is ok because of other things. For example, if the memory goes overboard, then kubernetes will just restart the pod, and that is ok because consumption gets committed regularly, and it is okay if messages get consumed more than once. It is an unfortunately trade-off to make but a valid one given the circumstances, and the likelihood that the GC metrics will normalize given more time, and also given a code clean up.

In looking into this ticket, I also learned that sometimes you have to chill out. For example, at the beginning of this ticket, there appeared to be a clear issue: the kafka logic. However, it did not become apparent that the issue could be divided into three separate issues: the consumer, the producer, and even the interrelationship between the concurrent producers and consumers that were running on multiple threads. As it turned, out the issue was within the consumer, but at first glance it appeared to be with the producer, and for no other reason that faulty thinking on my behalf. That is, the issue appeared to be with the producer because the producer appeared to be the only thing working. In actuality, that wasn’t true; rather, the consumer was doing just as much work by consuming other messages. Yet, this fact didn’t occur to me until after work. In fact, it was while taking a deep breath in the elevator that the clarity of mind finally happened. Probably, that day of researching and debugging the producer was wasted!

So in conclusion, this problem should have been tackled from the beginning with a different approach, that being the approach of really stripping down all the functionality and starting over, and with a clear mind.

<h2>May 27 2022</h2>
There are two major things on my mind today. This first is that i knowingly introduced tech debt into the SAC ecosystem at a very crucial level of the codebase. The second thing is that I believe I have touched upon a very central level of the challenges facing blockchain today. I will attest to both and resolve them in my mind, hopefully.

Regarding the first, it is more or less okay that I did this. For one, no functionality was broken. Initially, I thought that it was, but it turned out that I was wrong. In a sense, I got lucky because that functionality was preserved not because of the way I coded but because of advancements in underlying infrastructure, so still there was bad coding on my part. Ether way, I did what I had to do I suppose for the sake of the paperwork, so it is all good. Not perfect but all good for me. Anyway, the tech debt is ready to go but will it go out? I don't think so. By the way, this functionality in question was all that important. Simply put, it was logging errors, which even if we did keep logging them, the code never did anything about them anyway, so no harm done in the end. Still, I felt bad about it and wish I had just taken the hit and finished the better implementation.

Regarding the crypto research, it seems the ecosystem is at a crossroads. On one hand, monopolies are held over languages and tools, and for good reason, but on the other hand, more diversity is required in order for certain dreams to become reality. For example, the ethereum blockchain requires better client diversity in order to be secure. (https://hackernoon.com/ethereums-client-diversity-problem). There is no doubt that the problem is significant because it was exploited in previous attacks, and there is no solution currently addressing the problem.

In fact, the the monopoly on languages may be part of the problem. For example, the majority ETH client is built with Go. That is not surprising given that Go is such an amazing language (from what I hear), so it wouldn't surprise me that it is written Go. On top of that, it's probably the only client in Go, given that it's probably hard to find a reason to build another Go client when there already is one. People are like that: if it ain't broke don't fix it. The problem is that ethereum won't be a secure network if people think like that. That is because everybody will use the same client and thereby compromise the fundamental requirements of blockchain: that it be distributed, or may diverse is another word. In either case, the ownership of the software must be distributed so that no one person can control it.

So maybe I will look into this problem a little bit more and see what can be done about it.

<h2>May 24 2022</h2>
List of business ideas:

Map pop up on web pages for addresses.
Top three tweets from China, translated and posted on a twitter account daily.
Text Reminders: Text the reminder to this number and start getting reminders every day for, add a way to pay for it.
What is the difference between learning about computers and learning about computation? There definitely are differences, but they are tied together in the learning process.

What does it take to scale an ML algorithm? This is a question on my mind bc there seems to be a great deal of money in this area, but only sometimes. So what does it take? Beats me at this meoment. All I know is that there's some research on training models in a distributed systems, and that deploying models is different from training them. There is also the task of training models on the fly. So is ML eng the practice of deploying AND training them? I think that is true. Then there is what Glen's son said, where the model works but it doesn't scale, so the eng has to figure out how the optimize the model's time complexity.

<h2>May 23 2022</h2>
A few new questions are on my mind. The first is: What is to be gained from learning to monitor? The second is: is there a ceiling to the skill of software engineering? The third is: is there something missing in my career? The forth, but related to the third is: what is a worthwhile legacy to leave behind at the end of my career? (This line of thinking kind of devolves here a bit into questions like "What is meaningful? etc"). Yet another one is: what is to be gained from the the monitoring tickets of late? Is there a permanent skill to be gained from it, a new perspective?

Some things are answered. For one, working remotely is out of the question for any considerable length of time. It just feels bad to be stuck in a box, and it's better to be at an office and have some colleagues around and collaborate with them. It feels like there's a future that involves adventure and new experiences. Even my current episodes of remote work were successful because Aysh was there and the environment was new. So going back to the office is good.

At the same time, the remote option is nice to have. Let's see what happens when kids arrive.

Is there something to be gained from the monitoring work? In a sense yes. First, it's an exercise in iterative development. Second, it's an exercise in proving something, in debugging, perhaps. Thirdly, it's an exercise in the monitoring itself, which must be done anyway and learned about before any seniority can be claimed. Forthly, it's something new and interesting, so why not see what can be done with it, especially since it can be done in more than one way.

This last point is quite interesting. As it turns out, there are many ways to monitor the same thing. Or rather, there are many different metrics which give a slightly different angle on the same goal. For example, the cache miss metric has many options available, each giving a slightly different view point. One of them in errors, another one is cache refresh calls, another one is simply how many of the top 100K are there...all of them say the same thing with the details revealing the truth of it, and the real knowledge of how they're all connected being based in the code itself. As Teja said, there is coding and then there is coding with the intention of monitoring the code easily. It's not immediately clear how it differs, but there is a difference.

It begs the question of how the code can be changed to make inspecting it an easier task. In fact, there is an answer to that, but perhaps there isn't a clear one at the moment. Probably, code that is designed according to SOLID is easiest to monitor.

One of my goals is to fly around the world first class and debug software, it's kind of like John McAfee's early life. But moreso my goal is the build something great and have everybody use it. What are the steps to accomplish this? Perhaps the first step is the set up a website and start getting things built by other people but retaining the rights to the software. Then see if people use the tools, and then start putting them together. My list is quite long, so maybe it is worth the effort, and it will create jobs, and it will be my own business. This is probably better than starting out with a grand vision. Of course the ambition is there, but Rome wasn't built in a day, and neither will be a great work of software.

At the same time, there is more to learn about computation. This is different than whether there is more to learn about computers, but the answers to both of these questions is unclear.

Then there is the option, to simply up the salery. For instance, an ML engineer will get paid a lot more to scale ML algorithms than a full stack will get paid to build tools. Why is that? It's worth looking up.

<h2>May 18 2022</h2>
The emergence of Blockchain is provoked much thought, to say the least. Since it’s beginning, certain documentation has caught and held my interest, but others have stayed confounding even after rereads. An example of the former is the original Bitcoin white paper, which repeatedly sparked the imagination on many levels. For instance, it brought to light not only the fundamental problem of centralization, but it showed how to combine a variety of computer science topics. On top of that, it is well written, and so is a pleasure to read, and it just makes sense. Unfortunately this cannot be said about the many white papers from the thousands of blockchain startups. These works are lengthy and hard to follow, and they are numerous. Still, it may in fact be my impatience, ill-preparation, or familiarity with the wrong subset of literature, because the blockchain space is a massive industry worth billions of dollars. This particular fact is hard to ignore; there must be something there, but what exactly it is that is there is unclear. Hopefully, at least an actionable answer will become visible through some reflection.

Centralization - against the machine The DREAM vs the reality (where are the blockchains hosted etc). The anonymous-ness is not there. The history of finance and economic development. Diversity of coins. The tech itself, it’s not that crazy inventive. The trading of it.

Write about my understanding of blockchain. I am trying to make sense of my knowledge of blockchain, and the potential that it holds for the future. Protocal Labs, the trading, the white papers, the fact that dollars are still, is it a dream of communism, the developing world, Stellar, the tech itself, the problems with bitcoin, the white paper itself, the evolution of finance, the money that’s in it. What am I missing? All the start ups and all the coins, the volatility of the asset, conversations with Miles, the project i did myself, who actually knows what a blockchain is anyway? something about I always feel like I’m at the edge of a curve but I get in at the nick of time. Finance in general. some statistics: for criminal, how many nodes, where are the nodes, aggregration. what will break bitcoin? quantum computer.

-- as I was walking up today, i reflected on the knowledge that I was acquiring at work, these things about flagger and k8s and whatever, and i wondered is any of this knowledge permanant knowledge or is it trivial knowledge? and what exactly is the difference anyway? Idk myself, i guess permanent knowledge is some concept, like that flagger applies this gradual transition concept, or that canary deployments are a thing to consider when design CD pipelines, and trivial is something about how flagger works, or that the app is called flagger, but that does’n really satisfy me, bc in 10 years the concept of CD pipelines may be totally different too, maybe flagger will be built into k8s in 10 years, so it won’t help to know the problems with k8s, but more so permanent knowledge something that remains useful after flagger has gone away, and what will that be? i don’t know, i feel like it is just the perseverance of debugging, and research, but that is a process. there is also something fundamental about computer science, like just learning about the computers how they work, how the systems work, but then again than knowledge is lucrative but not permanent because the systems will be different from now, so what, i don’t feel the greatest about the fact that my knowledge is a bunch a bugs that I’ve seen before, because that is not how i want to measure myself coming out of.

i’d say the concepts of distributed systems is some permanent knowledge, that this these mental models of events and systems, they are a fleshing out of cap theorem in a sense. and containerization, it is a deepening of my understanding of containers the concept and layers of abstraction.

was learning nand to tetris permanent knowledge? maybe idk.

<h2>May 3 2022</h2>
Meetings are part of life, and this is true for software engineers as much as anyone else. Many things get discussed at meetings, and if one pays attention, then a good discussion can arise.

Debating definitions are a part of meetings for engineers. Today, for example, a debate came up over the meaning of an event stream. One side of the argument was that it tracks the changes of data to a data source. The other side argued that it tracked any changes to the data, even if the values in the data didn’t change. It is a subtle difference but an important one because it determines what gets published to the event stream. At the end of the day, the answers depends on what the consumer wants, which in this case was the former and not the latter…but it could have been the latter given a proper use case. One possible use case for the latter is that client wants to know of any attempted changes to the data source, even if the changes didn’t result in any changes to the data’s values. However, this is not what the client wanted. So, in the end, the definition ended up being the former, and the meeting dispersed.

Yet, it would have been nice if the definition ended up being the latter. One reason is that the team would have less work. That is, less logic would be required when making the publishings to the event stream, and our code would be simpler. Then, we could call this ticket done and deliver some value to the clients. Of course, there may be too many events going to the topic but at least there will be some events at all, when previously there were none. For the clients, this is ok because they won’t break, since consuming is pull-based rather than push-based. So, something gets done, and there is still the opportunity to optimize it in the future, and the managers will be happy since the ticket gets across the board.

It may be apparent now that there are various reasons for debating the definitions of things. Some of them are political, for the purposes freeing up one’s time or getting away with as little as possible and still making the managers happy. It turns out that this desire can sometimes conflict with the needs of the customer, who may want something more than what the engineer can do, or wants to do with the time allotted. The conflict arises because time is limited and the list of tasks is long, so engineers have to decide what doesn’t need to be done. In this example, it was whether or not to filter events. In the end, the manager won and the ticket was given more and energy.

It could have ended differently, but not likely. One way would have been to show that the additional logic would result in no difference in the quantity of events published. Another angle would have been to present a better business use case for the latter. In end, however, the best way would have been to simple get out the ticket and say the rest will be don latter, and then see if the remaining work actually got prioritized.

<h2>May 4 2022</h2>
Here is an example of looking into a new tool. Recently, project to automate namespace creation throws an error about a failed host look up. The errors look familiar; it’s been seen before, even discussed in the channels. At first glance, a simple mapping is broken, maybe it can be fixed quickly by reinstall, but that turns out to not work. Looking further, a quick inspection of the configs suggest things should be working. So what now? Probably do nothing and wait.

The tight coupling is apparent. In the past, it might have been exciting to looking deeply into the issue, but today, the root cause is obvious: the tool is too tightly coupled to the cli tools. Instead, they should have relied on the existing kubernetes infrastructure and gotten it working before creating a new cluster. Once realizing this, it became obvious that this tool wasn’t going to work out, and that time was spent better elsewhere. It’s not my problem.

A year ago, however, the response would have been very different. That is: dive into the the issue and fix it, maybe ask about it, maybe write about it, tell others about the hacks needed to get it to work. In fact it may still be a quick fix (some mapping is probably broken), after which things would continue smoothly. However, the effort is still not worth the time since the task was exploratory in the first place, and there will come a time when the project is readily available, so it’s just better to be patient. Reflecting on this experience, it became clear that that’s quite a change in perspective from the beginning of my engineering days.

Yet, at the same time, there is value in solving bugs because they fix the gaps in one’s knowledge. A good engineer is always growing, and that mean expanding one’s knowledge. Therefore, there is good reason to solve the bug, even if it doesn’t deserve the businesses time. Even my skip-level said one of his only regrets was not pursuing problems for their own sake, even if the value to the business wasn’t obvious. That really highlights that the eternal dilemma for the engineer is: what to work on? This is because the systems are too big for any one person, just like life…but that is a story for another time.

Getting the answers to that question is perhaps why tabulating the fruits of my labor over the past few years has suddenly become of great interest. Certainly there are a host of material improvements, and in addition to that, my knowledge of computer science and software engineering has increased considerably. Additionally, my the tools for observing myself and the world around me have increased and developed. This is all good, and I am fortunate and grateful. Now, with regards to these things, some of them changes are concrete and measurable (such as net worth accumulation), and some of them remain qualitative (such as the degree of my improvement as an engineer). The hope is to make concrete, with examples, the qualitative changes.
<br/>
	
<h2>8/17/2021 A call for debugging tools</h2>
There are many great debugging tools out there, but there could be many more. One great one that exists already is remote debugging; this really impressed me at first sight because of how many moving parts are required to make it work. There are the two connections to the remote server (one for code syncing and one for communicating the debugging steps), and also the logic of stepping through the code itself. In fact, this example illustrates very well how to combine two good things into one great thing: that is, it combines the concept of debugging with remote syncing. Perhaps, future debugging tools will also arise from new combinations.

One field in which better debugging tools are greatly needed is in the realm of Kubernetes. Recently, it came to my attention that the flow from external network to the server port was a winding path. First, the server needs to be exposed to the right port through the Docker container. Then, the docker container needs to map to a Server Object, and lastly, an External Ingress needs to connect to the server port. In total, that amounts to at least four, maybe five different ports, and the way that engineers do it currently is to simply read the files and remember them. Naturally, it can be a challenge keep all of this in one’s head.

If one of the connections is misconfigured, this will became a challenge to debug because an Ingress will only throw a 502, and that is not descriptive enough. This is because it is possible that the Ingress throws 502 for other reasons, such as a firewall, or something else related to the network. So, it would be nice if one could quickly and easily rule out port mappings. One way would be to have a program visualize the port mappings. This would put a mental model to paper, so to speak, and really help developers see the typos.

Some may say that remembering ports is easy, but it’s not. This is because developers often work with combinations of 8, such as 80 or 8080 or 8081, and this can get confusing. For example, an Ingress will typically expose 80 but map to a Service port that is different than 80, but that port will likely be 8080 because 8080 is a default port in web applications. At least in a visualization, it would be easy to see the differences, and maybe even color-code them. If the argument still feels tenuous, consider that it may have been challenging to follow this paragraph with all the different ports being mentioned; now consider working with them in code!

The tool could be even better with a way to ping the application and stop along the way. In this way, the tool would resemble current debuggers’ ability to pause execution. The caller could read the details of the request, and inspect the node at which the request has stopped. This would be really interesting if it were possible, but it is unclear to me if such a thing is possible right now. But what is definitely possible right now is to misconfigure port mappings and not see it. It has happened to me, and my bet is that it has happened to others…and my use cases have only been for simple Kubernetes applications.

It would be really great to know what other Kubernetes debugging strategies are out there, but if this one were built, it would be good. It is also an example of using combinations: visualizations are combined with debugging logic, which are combined with tracing…it’s almost as many moving parts as Kubernetes itself! Maybe a simpler place to start would be an IDA plugin that analyzes helm charts along with application configurations. This would be more proactive than debugging, which at the end of the day is the best outcome. Please feel free to share your own tips for debugging Kubernetes!

<h2>How Programmers Think, December 2019</h2>
<p>
by Adrian Jewell (www.adrianjewell.com)

(Thank you for reading! Feedback greatly appreciated.)

VIDEO PRESENTATION: Part 1: https://youtu.be/6B85OM0PI_E Part 2: https://youtu.be/W-iRrE0l6i0 Part 3: https://youtu.be/PvZApIKFshY

Introduction (Know)

This treatise contains everything the lay person needs to understand software engineering. In fact, it might be good idea for more people to go into the field because software engineers are in high demand. This is known because the website Linkedin.com, recently posted 335,000 software engineer jobs in the United States. Now, it is the author's position that while there are there are 10000 coding courses on Udemy, and 7,020,000,000 results on Google, the opinions contained herein are the gems of knowledge one needs to develop professional-grade skills in computer programming.

Trust in the author's opinion. He is a software engineer with several years of experience. He taught himself how to code as a teenager, and later on, did a coding bootcamp to help himself break into the field. He worked in the industry, and also worked full-time as a coding instructor. During this time, he learned a valuable lesson:

Thinking correctly will allow the problem solver to easily teach him/herself anything programming-related.
Study this document, and you will be able to master any skill in coding, and more, in a very short time, without any hand-holding that usually happens in online courses, and that will make you very powerful. 

The Process:

The fundamental skill is software engineering is reasoning about problems in terms of inputs and outputs:

INPUTS -> OUTPUTS
This may sound simplistic or contrived, but actually it is not. To understand how an engineer accomplishes this, we start with a real world problem. Let’s say that you want to build an app for your phone that lets you read emails. If you want to build this application, you will probably be envisioning yourself using the app, in a scenario such as this:

As a user, I want to go on the app and view my emails.  
The above expresses how the software engineer thinks about the particular idea in his or her mind. In actuality, this particular sentence isn’t actually saying anything different that what we originally said in the previous paragraph, but it additionally implies a greater degree of specificity. Let’s think for a minute about why that is the case:

To start, there are probably some other requirements for this phone app, such as:

As a user, I want to go on the app and see my emails, and NOT OTHER PEOPLE’S. 
The addendum may have suprised a few people, causing them to respond like this: "Duh!"...Do not be so quick to react in that way. If somebody asked me to build that app for them, and he/she told me the first requirement,

As a user, I want to go on the app and view my emails.
I’d certainly ask him/her if the users wants to only see their own emails, or whether user want to see their emails along with other peoples emails. In reality, this is a valid question because the original requirement doesn’t specify, and there are certainly scenarios where seeing others' emails is preferrable (such as parents monitoring children's internet activity). This may be a contrived example, but the only reason it is contrived is because when people talk about viewing email, they automatically assume the idea is to only see their own personal emails. This kind of thinking, however, is what engineers call jumping to conclusions, and that’s something to avoid when building software. 

Now, another thing that is probably true about the email app is:

As a user, I DO NOT want other people to be able to view my emails.  
This requirement might also be implied by the original statement, but it is actually not implied at all. Once again, in today’s world, people generally assume that emails are private and confidential, but it is very possible that this particular app does not treat emails as confidential information.

Now at this point, it is possible to see that clarification of requirements could go on for much longer, perhaps like this:

As a user, I want to view my emails…
        FROM ANYWHERE IN THE WORLD,
        AND THEY SHOULD LOAD QUICKLY,
        AND ANY EMAIL I SEND SHOULD NOT BE MODIFIED IN TRANSIT TO THE RECIPIENT.
Most people would expect an email app to meet these requirements. In fact, all of these mentioned requirements are very interesting and challenging software problems that engineers have tackled for many years, but that is besides the point. For now, simply understand that clarifying requirements is a major part of a software engineer's initial reasoning about a problem.

Remember, however, that this process of clarification is not the key skill in software engineering, but rather a tool to help the engineer succeed at the original task: viewing a problem in terms of its inputs and outputs. In the case of our example, the answer is as follows:

(Username and Password) -> (Emails associated with the Username)
The reader should see how the original line of inquiry led the software engineer to decide on these inputs and outputs. In case is it not clear, a brief explanation follows:

The engineer chose the username as an input because it is a "unique identifier" for the user. That is, the username can identify the user in such a way that every user is distinguishable from every other user. Armed with a username, the email app can filter for the emails associated with the user while excluding others. The password, similarly, is the way that the application verifies that users are in fact who they say they are (this is called authentication). In this way, only the user itself can view the emails associated therewith. Perhaps the decision to use username and password may be obvious, but the point of the exercise is not to solve a difficult problem but rather to highlight, in as detailed a way as possible, the thought process of software engineering.

To recap, the requirements are now solved as follows:

- As a user, I want to go on the app and see my emails, and NOT OTHER PEOPLE’S. [solved with a username]
- As a user, I DO NOT want other people to be able to view my emails.   [solved with a password]
The example ultimately highlights several things. Firstly, the reader can see how even something as commonplace and deceptively simple as an email application can require planning. Login screens are not that interesting, but they are pieces of software about which engineers seriously thought over, and the above discussion is just the beginning.

Now, the name for everything that just happened is called:

1. CLARIFYING THE PROBLEM
This is the first of six steps in a problem solving process that any programmer will execute when he/she writes a computer program. The remaining steps are as follows:

1. WRITE TEST CASES (examples)
2. BRAINSTORM STRATEGIES
3. PICK A STRATEGY
4. WRITE PSEUDO-CODE
5. WRITE CODE
6. VERIFY/TEST (DONE THROUGHOUT THE WHOLE PROCESS)
It will take some time to explain this process, but rest assured that mastering it will enable the reader to do software engineering.

Also notice that both “WRITE TEST CASES” and “CLARIFY THE PROBLEM” claim to be the first step. That is intentional because these steps are one and same, but with slightly different names and looks.

Continuing with the example of the email application will illustrate this point. Recall the decision for inputs and outputs:

(Username and Password) -> (The Emails associated with the Username)
Does the programmer have enough information to begin building the app? The answer is no, because more questions must be answered before any programmer get started. Some of these are:

What is a valid username?
What is a valid password?

What happens when invalid credentials are entered?
What happens when empty credentials are entered?

How many of the users emails do we want to return? 
The software engineer must first answer these questions because these questions have more than one answer. Thus, the engineer must answer them, and once answered there may be even more questions worth asking and answering. Given the matter, one might notice that these questions are slightly more specific than the first questions that were asked earlier. Therefore, they fall under the category of “TEST CASES” rather than “CLARIFYING THE QUESTION.” Let me reiterate: both categories are very closely related to each other, and writing these tests cases is extremely important, perhaps the most important part of computer programming.

At this point, it is the author's hope that reader is becomming interested in the process of software engineering. The reader also may also notice that the coding has yet to be done. Isn't programming about writing code? Yes, but remember, the article's goal is to explain the process of computer programming, and computer programming actually starts with the process of trying to understand the problem as clearly as possible. Once the programmer understands the problem, then he/she can easily move onto the coding-related steps. The remaining portion of this introduction with walk through those remaining steps, but in order to do so, we still use a new example.

__

For sake of clarity, a different example will illustrate the remaining five steps in the problem solving process. While it is possible to continue explaining the steps using the example of the email application, the truth is that building an email application requires specific technical knowledge that will hinder, more than help, in the explanation of the problem solving process. Believe it or not, the problem of an email application can actually be a very difficult one. So, for the purposes of this article, a simple mathematical problem will suffice.

That task is to decide whether two numbers add up to a third number. This may sound too simple, but that is a good thing because it will allow the reader to concentrate solely on the thought process, and it will be become clear how in-depth one is able to go into one's way of thinking. Now, recall once again that the goal of the engineer is to transform the problem into a series of inputs and outputs:

INPUTS -> OUTPUTS
The first step is to ask clarifying questions, and thankfully, there are only a few necessary clarifications to be made in this problem. Firstly, can assume that numbers are real numbers. They can be positive or negative, or zero. We can also assume the addition operator works as is normally expected. In short, these are reasonable assumptions to be made, but the engineer must clarify them because it is certainly feasible that the problem's writer had other mathematical definitions in mind, however unlikely that may be. Once again, see how jumping to conclusions can possible hurt the engineer, but enough of this. Now, it is time to accomplish the task, and doing so would probably result in writing the inputs and outputs in a way such as this:

Three numbers (a, b, c) -> True or False
In other words: given the three numbers (expressed symbolically here), output whether or not they add up to the third number; the output is either a “Yes” (True) or “No” (False). To prove one's understanding, write some test cases that give correct sets inputs and outputs, for example:

1,2 , 3 => True 
This is clearly true because one plus two equals three. Here is another one:

3,4 , 10 => False 
And a few more:

-3,0 , 3 => False 
-4,-4 , -8 => True
On the topic of converting problems into inputs and outputs, remember to approach this step very carefully and always seek confirmation from whoever wrote the problem. This step is first and foremost an exercise in reading, and feedback will ne very helpful. Additionally, alwasy remember that generating a good list of test cases is necessary, but can be very challenging. Notice that the test cases take 0 and negative numbers into account. These are what engineers call "edge cases", because they are often unlike the usual test cases. As a rule of thumb, always be on the lookout for edge cases. The tricky thing is that edge cases are often the hardest to think of, they can be the most informative examples.

Another reason that generating tests cases is important is because it will often be the case that the engineer doesn't know how to transform the inputs into the outputs. With this particularly problem being simple, the reader can easily see the answer, but that won't always be the case. When the engineer gets stuck, he/she needs to come up with more test cases, and often simpler ones.

After coming up with test cases, the next step is to brainstorm strategies. Maybe in your mind, there is only one approach to this problem, but to an engineer, there is always more than one way to accomplish something (maybe even software engineering itself!), so here are a few of them:

1. Add the two numbers together, and compare the sum with the third number.
Here is another way:

2. Subtract the second number from the third number, and compare it with the first number.
The second solution is also valid. Perhaps, it is difficult to see how the two solutions differ at all. Although it is true that they fundamentally accomplish the same thing, they are not the same solution. This is because they perform different mathematical operations, and this might be an important detail for an engineer. It is important to appreciate the creativity that goes into finding multiple solutions, even for something as trivial as this problem.

It is also important to note that while this problem had two very clear solutions, there may certainly be more solutions, and conversely, it is often the case that no solutions come to mind during a problem. How to come up with solutions will also be a topic of in-depth discussion later on in the paper. The technique for doing this is perhaps the least understood of the engineer's skills, and it is still a field that the author personally feels is an area worth of academic research.

It is process requiring both creativity and discipline. In practice, coming up with solutions can be challenging because it requires the engineer to be aware of his/her own thoughts, and then be able to express, in words, a series of steps that describe the inputs being transformed into the outputs. Pattern recognition requires insight, and to describe that insight requires clarity of thought, and attention to detail, and simply skill in communication. There are strategies to help with this process, and they are outlined later on the discussion.

Having arrived at two solutions, the next step in the process is to pick one of them. This means to weigh the trade offs of one solution over another. That is, when evaluating solutions, there will usually be pros and cons for each, so the engineer must do the work evaluating those pros and cons.

Typically, there will be a trade off in terms of the time efficiency of one solution runs over another, and this is a useful metric because users care about the speed of their computer programs. Connecting this back to the two available solutions currently at the engineer's disposal, it is possible that one of these solutions will run faster than the other because of the computer's particular way of doing mathematical operations. That is, sometimes an addition operation will happen faster than a subtraction operation on a computer, or vice versa. This may be a trivial performance increase on a modern machine, but imagine a hypothetical scenario from a time in the past, when machines were rudimentary. In that era, solutions such as these could present very significant trade offs. In short, deciding on a strategy must take place in the problem solving process, and it is important to know that will involve trade offs, like all big life decisions.

For our example, the engineer will choose the first solution, bringing him or her to the fourth step:

4. WRITE PSEUDO-CODE
Finally, a step involving coding...sort of. That is, code that is not really code, but more of an in-between of English and code which engineers call pseudo-code. In pseudo code, a description of the chosen solution might look like this:

1. numbers a, b, c
2. d = a + b 
4. return d == c
Try to understand this, line by line. In line one, the engineer recognizes the three numbers as existing (yes, that is a step). In line two, calculate the sum of the first two numbers and assign it a symbol. In line three, evalulate whether the sum equals the third number...it's pseudo code because it looks like code, but is not formal syntax of any particular programming language. For those not verse in conding, the word "return" is jargon for "provide as output: ".

There was not much pseudo-code in this example, but in practice, writing peusdo can actually be one of the hardest steps. If it is hard to come up with pseudo-code, the engineer probably didn't think clearly enough about the strategy, and may need to subdivide the problem. When this occurs, doing more test cases until the process becomes so engrained in the mind that it flows out easily and quickly in words is a helpful technique.

There is also the problem of how exactly to write pseudo-code. A rule of thumb is to put every sentence into a line of code and subdivide the problem.

After having written pseudocode, implement (write out) the solution in real code using the pseudo code as a guide. In order to do this, one needs to know how to write computer programs and run those programs on a computer. Because this guide is meant for an audience that may not know how to code, the author has taken every effort to make the following code intuitive to understand, but it will invariable happen that there may be confusions about why something was written in a particular way. Additionaly, because this article is not an introduction to computer programming languages nor an introduction to the inner workings of computing systems, the discussion of how this code exactly works will be left to other resources. With that said, please enjoy the final product of the problem solving process followed thus far:

function TwoNumbersAddToThird(a, b, c) {
    return (a + b) === c;
}   
This is an implementation in a programming language called javascript. Even without any formal study in programming languages, the average reader can probably grasp how this function works, and how it relates to the peusdo-code, also written above. If the reader saw how the pseudo code translated into code, then he/she should be encouraged by his or her newly discovered sense. However, if the connection was not apparent, then it would be helpful for the reader to take a CodeAcademy.com introductory course on Python or Javascript and then revisit this example. That being said, it is not necessary for the student to be skilled at programming to appreciate this knowledge, but know that in harder problems, the process of translating pseudo code into real code is where software engineer becomes the computer programmer, and the engineer's skill and knowledge in working with computers, and perhaps a specific type of computer, bears ripe fruit.

Despite any challenges when going from pseudo-code to code, it is still the most colorful process of all the six, and this is because coding, like many wonderful things, is messy. At the same time, grit is not be undervalued here, because grit enables engineers to do what it called “DEBUGGING” code...that, the the process of writing code, running the code, having the code output the wrong answer, then figuring out why the code produced the wrong answer, and rewriting the code. The truth is: when one writes code, one does not always know what one writes until running it, and developing the ability to write 100% correct code the first time takes years, and actually never is fully achieved.

Therefore, debugging will happen, and to do it well takes an inquisitive mind, like that of an inspector. In fact, amongst all the parts of building software, debugging is most fun for the author. There something energizing about inspecting broken software. It is like the urge to stractch an itch: the urge to scratch fills the body with energy and makes the body perform the scratch, even if that person is really tired and does not want to move at all. With code as well, if the engineer wants to find out why something broke, he/she will often not stop until fully understanding the root causeg.

After all that debugging, if the engineer tests the code and it works, then congrats, the problem is solved! For the aspiring engineer, solve a minimum of one hundred and fifty of these problems (log onto either Codesignal.com or Leetcode.com to find problems). After that, keep practicing until solving a medium-level problem within forty-five minutes is easy, then apply for a job as a software engineer. Of course, that number is a rough estimate, casually recalled by the author as the number of LeetCode.com problems that Google thinks an aspiring engineer should solve before one is ready to work for them.

An Exercise: (WANT TO KNOW)

Think of a problem that you want to solve, and document your thoughts and conclusions as you go through problem solving process. It can be any problem, and it doesn't have to be computer programming problem.

Some questions to ask yourself are: Can I think of the problem in terms of inputs and outputs? Where do I get stuck in the process? What gets you unstuck?

How To Brainstorm Strategies: (LEARNED)

Lets say that the problem is to figure out how the following inputs convert to the following outputs:

[2, -1, 1] => [1, -1, 2]
[3, -1, 2] => [2, -1, 3] 
[3, -1, 0] => [0, -1, 3]
If the engineer doesn't know the answer, he/she will start with some simple observations, such as that every single array has three numbers, and that the middle number is always -1. This will naturally lead to the observation that those two nonnegative inputs become sorted in the process of an input changing into an output (excluding the -1). These observations lead to even more intersting observations. For example, presence of the -1 illuminates a subtle pattern: that the position of the -1 doesn't change when an input becomes an output. From these collective observations, the explanation for how inputs turn into outputs will begin to crystallize in the mind. Perhaps, it becomes clear that each test case's input simply has its first and last element swapped with the other. More formally stated:

Swap the first element with the last element.
The above statement is an example of what engineers call a strategy, discovered via the process of making more and more sophisticated observations, ending in the discovery of how the input becomes the output. Regarding the written strategy, it should be a relatively quick procedure to verify that it actually does describe all the test cases, so see that it does.

Regarding the process of arriving at the strategy, the author has no clue, but would very much like to know, what happens in the brain when an engineer converges on a strategy. If the author attempted to eloquently describe a theory of the mental mechanism involved in such a task, it would be sufficient to say that mind has a way of feeding upon itself, using the result of previous thought as material for the next round of pattern recognition. In truth, however, the author cannot see into the brain, and so has no idea what happens.

Therefore, how this is exactly accomplished is of great academic importance, for the sheer fact that all artistic pursuits include these moments of clarity: a few seconds of sudden knowledge of a pattern exists, the precise details of which naturally dependent on the medium of art being pursued. This moment of clarity is so satisfying, yet so illusive a feeling that the author feel warranted to request an in-depth study, should one not already be underway.

In case it wasn't clear, that particular moment in software engineering is the instant where all of the patterns that the engineer had derived from his or her observations suddenly congeal into the series of instructions that must be performed in order to transform the input into the output. In fact, the beauty and desirability of this feeling is such that author also requests a thorough study of why people seek to have this feeling.

In short, this kind of thinking bears striking resemblance to the intellectual musings that arise when immersed in the psychedelic experience of reality bending in strange loops. That is to say, it's pretty trippy to think about this kind of stuff. And the truth is that this carefully rethinking of one's own thoughts is a laborious process. Until the time comes when it is not, the engineer just has to do it. Hopefully there come a time when coding is an effortless process, but in the meantime, the mental labor of translating language into code is quite mysterious in and of itself; despite the strong desire to alleviate birth pains containeed therein, the miracle of the mind being able to it in the first place, yet be avoidant to it, and also be able perform amazing feats of resourcefullness through it, all at the same time, merits an academic investigation of large scale. As a message to powerful institutions and governments, please stop fighting wars and put resources into answering questions like these.

The author's opinion is that the only guaranteed way to successfully make this translation is to subdivide the problem. In order to understand it, let us take the previous set of test cases as a subdivion of a larger test case, and make some connections. Here is the expanded set of test cases:

[2, -1, 1] => [1, -1, 2]
[3, -1, 2] => [2, -1, 3] 
[3, -1, 0] => [0, -1, 3]
+
[-1, 4, 2] => [-1, 2, 4]
[5, 0, -1] => [5, 0, -1]
The first three tests are of course identical for the former set, and the next two are new cases of inputs and outputs.

Let the reader once again make some observations. The new test cases are similar in terms of length, containing a -1, output being swapped, and having a -1 which does not move, but are also different in one single way: the placement of the -1. Pondering this should lead the problem solver to arrive at the observation that while the -1 might be placed in a different position, the other two numbers still simply get swapped with one another.

Putting all of this together into a pattern that accurately describes all of the test cases would be:

Swap the two numbers are not equal to -1.
Lo and behold, a new strategy is born, and let the reader understand how subdivision applies here. Looking at this strategy reveals how the initial strategy is buried within this new strategy. That is, if the position of the -1 is in the middle of the three numbers, then the swapping that occurs would be identical to the kind of swapping done in the intitially proposed strategy (that of simply swapping the first and last element.) Of course, if the position of the -1 isn't the middle number, then certain other kinds of swapping would need to happen...for instance, perhaps instead swapping first and second element. Thus, it is fair to say that not only does the new solution encapuslate the original solution, but it accounts for other transformations too. Appreciate how this creation of a hierarchy of logical operations amounts to subdivision much in the way that a tree trunk branches off into many more than were started with.

In this way, subdivision speaks to how one strategy can be a smaller, individually describable strategy of a more complex strategy. Also notice that an example from nature, that of a tree, serves quite well as the analogy to explain this concept. In short, it is a movement from the simple towards the complex, using the image of the tree as a helper for the mind to conceive of strategies. Like the branches, strategies relate to one another in the way that a larger trunk encapsulates the simpler strategies. The technique of subdivision, therefore, is to perform the congition required to understand the problem in this particular way, and in doing so, understand the problem better.

To describe subdivision another way, let us return to the strategy under analysis:

Swap the two numbers not equal to -1.
It may be possible that somebody simply asks an engineer today to write a program to perform the above task, and the engineer doesn't know how to code it. At this point, the engineer will attempt to break the problem into smaller chunks that he/she does in fact know how to code. How this is done will now be demonstrated:

Given the above the strategy, the solutions to such a division would probably look like this:

First, find the location of -1. 
Second, swap the other two numbers.
Written another possible way is:

First, find the two valid numbers.
Second, swap them.
In fat, it can sometimes be unintuitive to see this subdivision. This is because the concept of finding things before moving things is an apparent step in people's minds. Yet, if people paid attention very closely to their minds, they would know that in their own lives, whenever they want to move somethings, they must first locate the thing to be moved. The reason that this is true is because people get nervous when they realize they lost the things they were trying to move.

Consider, for instance, a hypothetical situation where you want to take out your favorite shirt from the dresser, but when you open the dresser to take it out, you realize it's not there. If this happens, you will start wondering where it is, but the only reason you care about where its whereabouts is because you want to move it. Certainly there are other reasons to care about where is located, but for the sake of this exercise, simply understand that the anxiety of not knowing the whereabouts of an object one wants to move establishes the psychological construct of the need to find the thing as a precursor to moving the thing.

In this way, the programmer studies the physical nature of things, drawing inspiration from it when thinking of ways to subdivide problems. In fact, the author is very interested in exploring the connection more.

Continuing forward, the coder will a find ultimately find a way to explain the strategy in a practical way such as this (with the two sudivided options referenced in brackets:)

If the -1 is in first position: [find the -1]
    Swap the second and the third elements. [swap]
If the -1 is in second position:
    Swap the first and the last elements.
If the -1 is in third position:
    Swap the first and the second elements.
Notice here how the new instructions demonstrate certain other kinds of subdivision, a subdivision that brings the instructions into a physical realm, as if the person reading the instructions was looking at the numbers on a chalkboard or as blocks on the ground. This reference to the physical act of tracking things emphasizes that inputs and outputs are actual things being manipulated as they existed in a physical world.

Also notice the strategy for the smaller set of inputs contained therein. "Swap the first and the last elements." There it is, clear as day! It was not hard to make this observation when the more complex strategy is already subdivided for us to see, but in the situation where one is first given the more complex strategy without subdivions, it is very difficult to make those subdivisions oneself.

This makes the challenge of subdividing down exemplifies what mathematicians call NP problems. NP Problems can time a long time to solve, but it is a very quick process to verify a possible solution. Subdividing is a kind of this problem because making subdivisions can take a long time, but given a set of possible subdivisions to any given strategy, it is easy to tell which ones are correctly contained in the parent strategy.

On another note, it may occur to the reader that the subdivisions being described could in fact be subdivided more, perhaps into physical movements of the body or eyes and more detailed biological processes in the human body, etc. It is the engineer's job to know which 'level of abstraction' is best suited for trasnforming into code, and any software engineer will gain this knowledge through practice.

There you have it: subdivision highlights the ways in which the engineer reaches an understanding of his/her mental processes as he/she transform inputs into outputs, and brings the engineer 'closer to the code', so that implementing the strategy becomes easier. Certainly, the journey doesn't stop here. In fact, it just began, for the task is now to implement the strategy. But that will not be part of this discussion, for "Where there is a will, there is a way." and the programmer trusts in his/her research skills and resourcefullness.

As a final note, it is worth mentioning certain strategies that engineers employ while coding. The first is debugging. When debugging, the engineer look at code very closely while it is running. It is supremely important to master this skill. The second is doing code on paper. The profound truth about software engineering is that software often cannot be understood when it is read or written. Therefore, the engineer must actually run the code in his/her mind, step by step, in order to fully understand the code. Literature for how to perform these two technique is abundant, so the author will simply highlight their common usage.

With that, this concludes the discussion on how programmers think. Thank you again reading, and please leave feedback!

-- The tips below will help an individual get started in coding.

Tips to Get Started:

Take a free online coding course (Codecademy.com is good, python or javascript are good to start).
Ask an engineer to teach you how to debug, do code on paper, and "research documentation."
Do problems on leetcode.com and codesignal.com ( for codesignal: arcade or interview problems).
Apply the ideas in this paper to the problems.	
</p>
	
	<h2>Music and Coding</h2>
Is it just me, or have other people noticed that software engineers are also often musicians, or at least, huge lovers of music? In my work and studies over the years, I’ve found music-making and coding use the same kind of thinking. In the following article, I’ll explain music from the perspective of computer programming using a common language, and hopefully, I’ll be able to illuminate similarities between these arguably disparate disciplines.

To start, I think the main way music and coding are similar is that at their heart, they’re both forms of state management. To explain this connection, let’s start with an example.

Let the Music Play
Begin by imagining the melody to your favorite song. If you can’t remember one, think about Fur Elise by Beethoven. Specifically, think about the opening trill between E and D# that opens the song’s first phrase. If you can’t remember Fur Elise, think about “Hot Cross Buns” or “Row Row Row Your Boat.” Hear the melody in your head and try to be aware of your feelings as you sing through it. Specifically, become aware of how your mood changes from start to finish; every note, the act of discerning it from the others, marks a distinct feeling inside. Do this a few times and you’ll become aware your mood changes as the song progresses. In fact, we could refer to the change in mood as a change in the state of our emotions, or simply, a “change in state.”

That word “state” should ring a bell to programmers — we work with state all the time in React components and Redux stores. In fact, the idea of a state permeates all of Computer Science, from concrete examples to more abstract ones. Physically speaking state can be a tangible thing, with the registers of the CPU and all electronic impulses moving through the computer at any given moment. PC Memory is also essentially a state with a large number of possible configurations. We can also think of state conceptually by defining it as what is inside our head as we conceive of an input, perform the logic with our brains, and end with an output. For example, run an algorithm through your head and you’ll know what I’m talking about. You’re tracking variables, and everything you’re tracking amounts to the state. Let’s connect this idea back to the experience of music-making.  

Now that we know what “state” is, we can understand how it can change within us as we make or listen to music. Is it really so far-fetched of an idea? I don’t think so, but whether or not you’re convinced thus far, notice I was able to describe music’s effect on us with the vocabulary of a well-known programming concept. This is good because it means we can use the same language to describe both coding and music.

Mood, or The Meaning of Movement
This leads to the idea that when music “moves us”, the mind is simply changing its state. People can acknowledge that music compels them to dance, and in this sense, the music is moving, and yes, compels us to get up and dance. Still, the music didn’t actually move a person with it’s proverbial arms. Additionally, is it not true that people will sit in stillness and still feel deeply moved by music? Since it is so, the feeling of being “moved” is an internal experience, a reaction to music, or a change in state. Physics is the basis for this claim, which links change to motion, as well as to time. We often say a program is “running,” which further links the concepts of change and motion, because it’s in the middle of changing its state.

Adding another layer to the discussion, it is also possible to say the state change is meaningful to the listener in some way. When I say “meaningful,” I mean we respond to music and express our reaction. Certainly, music is meaningful to people and that’s what makes it so wonderful. We might be able to say the same thing about computer programming in the sense that the programmer cares very much about the outcome of the program and this is a key insight: a change from one state to another matters a great deal to the consumer of that new state. Circling back, observe again I’ve again used technical jargon to describe the fundamental experience of music. Think about it: your mood is your state and your change in mood in response to the music is basically the same thing as logical operations upon a state object. The music flows, we respond to it, and then we make use of, or attribute, value to that experience.

You might be thinking, “But my mood wasn’t changing. I just listen to music and enjoy myself. I don’t track my mood during the piece. I really just have one mood during music listening: ecstasy!” This may be true but would you also agree you feel different after listening to enjoyable music? If so, you’re experiencing state change: moving from one state to another and then enjoying that experience and attaching value to it. Depending on their sensitivity, most people experience a state change in response to music.

Consider all of these points, play some music again, and reflect on whether you think what I’m describing is happening. If you’re still unsure, take this example: If I listen to some music to wake me up in the morning, I move from feeling tired to alert, and may even repeatedly use this strategy to wake myself up. Basically, I have access to a computer program for my body: my mood changes state, I find that new state useful, and therefore I attribute value to it. As such, the music automates a task I need to complete often, and this is exactly what technology is meant to do. If you agree with me, then congratulations, you’re thinking about music and programming as fundamentally similar concepts.

The Importance of Execution
Music and coding are related in other ways too.

For example, they both must be executed for them to have their desired effect, as opposed to being stable in space, like a painting. They’re both stored and repeated for later use, and both are inseparably tied to the technology available to them at the time. Just imagine what Frederic Chopin or Mozart would have composed with a computer from our modern era!

From another perspective, we might consider how the configuration of piano keys being pressed at any one point on a piano is astonishingly akin to the state of the memory registers in a CPU at any given point in time. It’s a neat idea! This and other little musings go to show that in thinking about both music and coding, it’s possible to see how people arrive at the idea of music and math having a lot in common.

Music and Coding: What are They Telling Us?
Another way in which music and computer programming are similar is that they are both representational. This is an interesting concept that deserves more explanation.  

What I mean by representational in computers is that you get to express a lot more than a simple command. When we write code, we are commanding the computer to perform millions of computations, most of which are beyond our awareness or comprehension. For example, if I render an image on an HTML Canvas, those ten to twelve characters of code equate to a very large number of computations by central processing units. Yet we are not completely aware of those computations. We know they happen but we don’t literally run all of those processes through our heads when we code. Rather, we acknowledge our code represents those instructions faithfully and perceive our code as representing something larger, the millions of computations the CPU or GPU must execute.

And music is nearly identical in this way because it represents something far greater than its intrinsic substance. Given a melody we like, we’d say its meaning is attributable to the feelings it evokes inside of us. It’s not the music that is by itself meaningful to us but all the feelings the music brings up that causes us to feel. In this sense, each note actually represents a complex series of executions, called life, something infinitely complicated we acquiesce to represent as music, and feel that music represents it accurately. For me, personally, this is probably the defining characteristic of music, differentiating it from just a collection of organized sounds.

One might be able to make an argument for the same similarity between programming and other forms of communication or other phenomena of nature, such as language.

Why Music and Coding are Special To Me
You may be wondering why I came to notice the similarities between music making and computer programming.

To start, coding found me largely by accident but it gave me a feeling that definitely wasn’t. In fact, it was quite special. It felt exactly like practicing the piano, something I absolutely love to do but with a few added perks…such as the feeling of euphoria after solving an algorithm. One rarely experiences this as a classical pianist, where the angst of playing a piece perfectly stems any lasting feeling of elation. With coding, there is great excitement; it bubbles up from deep down inside and takes over. It’s a discovery of movement, of power to control information. It felt quite good. Yet, when I looked up the solution from an expert, I realized how much more elegantly I could have coded my own solution, just like I could’ve performed Beethoven’s Fur Elise far more beautifully no matter how much I practice. Alas, I came full circle, where coding ended up being exactly like practicing an instrument!

So I think this deep connection is what connects the two disciplines. As I continue to study computers, I feel a deep similarity between playing music and coding that wasn’t immediately apparent when my coding journey began. I look forward to getting better at both in the next few years.	
</body>

</html>
